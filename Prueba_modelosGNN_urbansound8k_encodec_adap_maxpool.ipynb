{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    \n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def test(model, data, mask):\n",
    "    \n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(torch.argmax(out, dim = 1)[mask], data.y[mask])\n",
    "    return acc\n",
    "\n",
    "def train(model, data, epoch, enable):\n",
    "    \n",
    "    f_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = model.optimizer\n",
    "    epochs = epoch\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = f_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        acc = accuracy(torch.argmax(out, dim = 1)[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        val_acc = test(model, data, data.val_mask)\n",
    "\n",
    "        if enable == True:\n",
    "          if(epoch % 10 == 0):\n",
    "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
    "                  f'{acc*100:>6.2f}% |' f'Val Acc: {val_acc*100:.2f}%')\n",
    "          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Dropout\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, SAGEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "  def __init__(self, dim_in, dim_h, dim_out, heads=10):\n",
    "    super().__init__()\n",
    "    self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
    "    self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.001,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.5, training=self.training)\n",
    "    h = self.gat1(h, edge_index)\n",
    "    h = F.relu(h)\n",
    "    h = F.dropout(h, p=0.5, training=self.training)\n",
    "    h = self.gat2(h, edge_index)\n",
    "  \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "  def __init__(self, dim_in, dim_h, dim_out):\n",
    "    super().__init__()\n",
    "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
    "    self.gcn2 = GCNConv(dim_h, dim_out)\n",
    "    self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.001,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "  def forward(self, x, edge_index):\n",
    "    h = F.dropout(x, p=0.5, training=self.training)\n",
    "    h = self.gcn1(h, edge_index)\n",
    "    h = torch.relu(h)\n",
    "    h = F.dropout(h, p=0.5, training=self.training)\n",
    "    h = self.gcn2(h, edge_index)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, out_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                      lr=0.001,\n",
    "                                      weight_decay=5e-4)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        h = F.dropout(x, p=0.5)\n",
    "        h = self.conv1(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=0.5)\n",
    "        h = self.conv2(h, edge_index)\n",
    "       \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "import os.path as osp\n",
    "#import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MyOwnDatasetFixedKnn(Dataset):\n",
    "    def __init__(self, root, path, enable = False , transform=None, pre_transform=None, pre_filter=None):\n",
    "      self.path = path\n",
    "      self.enable = enable\n",
    "      super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.path\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "      if self.enable == False:\n",
    "        return [f'data_{i}.pt' for i in range(10)]\n",
    "      else: \n",
    "        return [f'data_{i}.pt' for i in range(109)]\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "path1 = \"UrbanSound8K_8276.csv\"\n",
    "path2 = \"TF_encodec_adap_maxpooling.hdf5\"\n",
    "dataset = MyOwnDatasetFixedKnn(root = \"./own_dataset/data_encodec_adap_maxpooling_fixed_knn\", path = [path1,path2])\n",
    "loader_dataset = DataLoader(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyOwnDatasetFixedKnn(10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAT\n",
    "\n",
    "  \n",
    "prom_acc_gat = []\n",
    "dev_values_gat = []\n",
    "num_epochs_gat = []\n",
    "\n",
    "#GCN\n",
    "\n",
    "\n",
    "prom_acc_gcn = []\n",
    "dev_values_gcn = []\n",
    "num_epochs_gcn = []\n",
    "\n",
    "#SAGE\n",
    "\n",
    "\n",
    "prom_acc_sage = []\n",
    "dev_values_sage = []\n",
    "num_epochs_sage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT\n",
      " accuracy mean: 11.86% | standard deviation: 0.01 | epochs: 30\n",
      "GCN\n",
      " accuracy mean: 11.28% | standard deviation: 0.01 | epochs: 30\n",
      "SAGE\n",
      " accuracy mean: 11.93% | standard deviation: 0.01 | epochs: 30\n",
      "\n",
      "==============================================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m       graphs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m       gat \u001b[39m=\u001b[39m GAT(\u001b[39m9600\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 21\u001b[0m       train(gat, graphs, epoch \u001b[39m=\u001b[39;49m i, enable \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     22\u001b[0m       acc_gat\u001b[39m.\u001b[39mappend(test(gat, graphs, graphs\u001b[39m.\u001b[39mtest_mask))\n\u001b[1;32m     24\u001b[0m \u001b[39m#==========================GCN===============================================  \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, epoch, enable)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     21\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 22\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     23\u001b[0m     loss \u001b[39m=\u001b[39m f_loss(out[data\u001b[39m.\u001b[39mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n\u001b[1;32m     24\u001b[0m     acc \u001b[39m=\u001b[39m accuracy(torch\u001b[39m.\u001b[39margmax(out, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)[data\u001b[39m.\u001b[39mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[1;32m     11\u001b[0m   h \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m---> 12\u001b[0m   h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgat1(h, edge_index)\n\u001b[1;32m     13\u001b[0m   h \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(h)\n\u001b[1;32m     14\u001b[0m   h \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(h, p\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:236\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe usage of \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39msimultaneously is currently not yet supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m form\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[39m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49m(x_l, x_r), edge_attr\u001b[39m=\u001b[39;49medge_attr,\n\u001b[1;32m    237\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    239\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:454\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 454\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    457\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:578\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    566\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    567\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    568\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    579\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/trabajo_grado/Proyecto_GNN/env/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:126\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    125\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m dim_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index\u001b[39m.\u001b[39;49mmax()):\n\u001b[1;32m    127\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncountered invalid \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdim_size\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m                              \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdim_size\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m but expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m                              \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>= \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax())\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(x, index, ptr, dim_size, dim, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(30,2230,200):\n",
    "#GAT\n",
    "\n",
    "  acc_gat = []\n",
    " \n",
    "\n",
    "#GCN\n",
    "\n",
    "  acc_gcn = []\n",
    "\n",
    "\n",
    "#SAGE\n",
    "\n",
    "  acc_sage = []\n",
    "\n",
    "\n",
    "  for n, graphs in enumerate(loader_dataset):\n",
    "#==========================GAT===============================================\n",
    "      graphs.to(device)\n",
    "      gat = GAT(9600, 20, 10).to(device)\n",
    "      train(gat, graphs, epoch = i, enable = False)\n",
    "      acc_gat.append(test(gat, graphs, graphs.test_mask))\n",
    "\n",
    "#==========================GCN===============================================  \n",
    "\n",
    "      \n",
    "      gcn = GCN(9600, 20, 10).to(device)\n",
    "      train(gcn, graphs, epoch = i, enable = False)\n",
    "      acc_gcn.append(test(gcn, graphs, graphs.test_mask))\n",
    "\n",
    "#==========================SAGE=============================================== \n",
    "\n",
    "      \n",
    "      g_sage = GraphSAGE(9600, 20, 10).to(device)\n",
    "      train(g_sage, graphs, epoch = i, enable = False)\n",
    "      acc_sage.append(test(g_sage, graphs, graphs.test_mask))\n",
    "\n",
    "#==========================GAT===============================================\n",
    "\n",
    "  prom_acc_gat.append(np.mean(acc_gat))\n",
    "  dev_values_gat.append(np.std(acc_gat))\n",
    "  num_epochs_gat.append(i)\n",
    "\n",
    "#==========================GCN===============================================  \n",
    "\n",
    "  prom_acc_gcn.append(np.mean(acc_gcn))\n",
    "  dev_values_gcn.append(np.std(acc_gcn))\n",
    "  num_epochs_gcn.append(i)\n",
    "\n",
    "#==========================SAGE===============================================  \n",
    "\n",
    "  prom_acc_sage.append(np.mean(acc_sage))\n",
    "  dev_values_sage.append(np.std(acc_sage))\n",
    "  num_epochs_sage.append(i)\n",
    "\n",
    "  print(f\"GAT\\n accuracy mean: {np.mean(acc_gat)*100:.2f}% | standard deviation: {np.std(acc_gat):.2f} | epochs: {i}\\n\"\n",
    "        f\"GCN\\n accuracy mean: {np.mean(acc_gcn)*100:.2f}% | standard deviation: {np.std(acc_gcn):.2f} | epochs: {i}\\n\"\n",
    "        f\"SAGE\\n accuracy mean: {np.mean(acc_sage)*100:.2f}% | standard deviation: {np.std(acc_sage):.2f} | epochs: {i}\\n\\n\"\n",
    "        f\"==============================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
